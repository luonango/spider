#!/usr/bin/python
# -*- coding: utf8 -*-


class
//*[@id="pl_weibo_direct"]/div/div[1]/div[2]/div[2]/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[1]/div[3]/div[2]/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[2]/div/div[1]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[2]/div/div[2]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[2]/div/div[3]/div/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[3]/div[2]/div[1]/div/div/div/div/div[2]/p

//*[@id="pl_weibo_direct"]/div/div[4]/div[1]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[4]/div[2]/div/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[4]/div[5]/div[2]/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[4]/div[6]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[4]/div[8]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[4]/div[13]/div/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[1]/div/div[2]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[1]/div/div[10]/div/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[1]/div/div[2]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[1]/div/div[3]/div/div[1]/dl/div/div[3]/div[1]/p

//*[@id="pl_weibo_direct"]/div/div[1]/div/div[13]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[1]/div/div[17]/div/div[1]/dl/div/div[3]/div[1]/p


//*[@id="pl_weibo_direct"]/div/div[1]/div/div[11]/div/div[1]/dl/div/div[3]/div[1]/p
//*[@id="pl_weibo_direct"]/div/div[1]/div/div[4]/div/div[1]/dl/div/div[3]/div[1]/p



//*[@id="pl_weibo_direct"]/div/div[2]/div/a[2]
<a href="/weibo/%25E5%25A5%25B6%25E7%25B2%2589%2520baby&amp;page=43" suda-data="key=tblog_search_weibo&amp;value=weibo_page" class="page next S_txt1 S_line1">ä¸‹ä¸€é¡µ</a>












//*[@id="pl_weibo_direct"]/div/div[2]/div/div[1]/div/div[1]/dl/div/div[3]/div[1]/p
    <p class="comment_txt" node-type="feed_list_content" nick-name="é—«è²__Lucky">
		è€å…¬è¯´æˆ‘å°èªæ˜æ²¡æœ‰å¤§èªæ˜ä¹Ÿæ²¡æœ‰å°±æ˜¯ä¸èªæ˜ï¼Œè®©æˆ‘ä¸ºäº†ä»–çš„<em class="red">baby</em>èªæ˜ï¼Œå¤©å¤©è®©æˆ‘å–å­•å¦‡<em class="red">å¥¶ç²‰</em>ï¼Œè¯´è¿™æ ·å­©å­ä¼šæ¯”æˆ‘å¼ºå¾ˆå¤šï¼Œä¸ä¼šéšæˆ‘<img src="http://img.t.sinajs.cn/t4/appstyle/expression/ext/normal/49/hatea_org.gif" title="[å“¼]" alt="[å“¼]" type="face">ï¼Œå¯æ˜¯å¤ªè…¥å‘³äº†ï¼Œå¤ªå®¹æ˜“ä¸Šç«ï¼Œå¤ªå®¹æ˜“å‘èƒ–äº†ï¼Œå–æˆæ°¢æ°”çƒäº†éƒ½ã€‚
		</p>


//*[@id="pl_weibo_direct"]/div/div[2]/div/div[2]/div/div[1]/dl/div/div[3]/div[1]/p
<p class="comment_txt" node-type="feed_list_content" nick-name="å•ªå•ªè´­å®˜ç½‘">
		ã€åˆ°è´§å•¦ï¼ï¼ï¼å•ªå•ªè´­å¤‡è´§çš„å¾·çˆ±å’Œé“ç½ç‰›æ <em class="red">å¥¶ç²‰</em>ä»Šå¤©å·²ä¸Šæ¶<img src="http://img.t.sinajs.cn/t4/appstyle/expression/ext/normal/3e/lxhhaobang_org.gif" title="[å¥½æ£’]" alt="[å¥½æ£’]" type="face">ã€‘å¦ˆå¦ˆæœ€çˆ±çš„è¿›å£<em class="red">å¥¶ç²‰</em>å“ç‰Œï¼šå¾·çˆ±ã€Hero <em class="red">Baby</em>ä»¥åŠé“ç½ç‰›æ <img src="http://img.t.sinajs.cn/t4/appstyle/expression/ext/normal/40/hearta_org.gif" title="[å¿ƒ]" alt="[å¿ƒ]" type="face">ï¼Œå•ªå•ªè´­ä»Šå¤©å·²å…¨æ–°ä¸Šæ¶ï¼å¤šä¸ªSKUå¯é€‰ï¼Œä¿ç¨åŒºå‘è´§ï¼Œå¾·å›½çˆ±ä»–ç¾å¥¶ç²‰2ç½è£…ä½è‡³196å…ƒåŒ…é‚®ï¼Œé“ç½è·å…°ç‰›æ å¥¶ç²‰2ç½è£…250å…ƒèµ·å¯é‡‡è´­ã€‚å¥½è´§ä½ä»·ï¼Œæƒ³è¦åˆ†é”€ï¼Œå°±æˆ³<a title="http://www.papago.hk/itemgroup.html?igId=12091&amp;listtype=max&amp;igId2=&amp;startprice=&amp;endprice=&amp;newproduct=false&amp;whCode=GZJC&amp;hasQuantity=false&amp;front.esCode=E&amp;sort=&amp;key=&amp;promoteType=&amp;oflag=&amp;location=&amp;new200=&amp;timeIndex=&amp;brandId=&amp;front.postFree=&amp;front.originCtId=&amp;front.stockUp=&amp;front.brandIds=&amp;front.shipment=&amp;front.importType=" href="http://t.cn/R5c11iD" target="_blank" mt="url" action-type="feed_list_url" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_url" class="W_linkb">http://t.cn/R5c11iD</a>
		</p>


//*[@id="pl_weibo_direct"]/div/div[1]/div[2]/div[2]/div[1]/dl/div/div[3]/div[1]/p
<p class="comment_txt" node-type="feed_list_content" nick-name="å­éªéº»éº»-">
		ä»Šæ™šè¡¨ç°ä¸€ä¸ªå­—ï¼Œæ£’ï¼ä¸€ç‚¹åŠæ‰é†’ç¬¬ä¸€æ¬¡ï¼Œå–äº†90ml<em class="red">å¥¶ç²‰</em>ç¡ç€äº†ï¼Œæœ€å…³é”®çš„æ˜¯ç°åœ¨ä¼šå–<em class="red">å¥¶ç²‰</em>äº†ï¼Œè™½ç„¶ä¸æ˜¯ç‰¹åˆ«æƒ…æ„¿ï¼Œä½†è‡³å°‘æ²¡é‚£ä¹ˆæŠ—æ‹’ã€‚å¥½çš„å¼€å§‹ï¼Œå®è´æ£’æ£’å“’<img src="http://img.t.sinajs.cn/t3/style/images/common/face/emimage/ee808e.png" width="20px" height="20px">ğŸ»<a href="http://weibo.com/n/%E5%AD%90%E9%AA%9Ebaby_?refer_flag=1001030001_" usercard="name=å­éªbaby_&amp;refer_flag=1001030001" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_at" target="_blank" class="W_linkb">@å­éª<em class="red">baby</em>_</a>
		</p>

<p class="comment_txt" node-type="feed_list_content" nick-name="R_qiong">
		ä»Šå¤©åœ¨ä¼ è¯´ä¸­æœ€é è°±çš„ <a href="http://weibo.com/n/%E7%BD%91%E6%98%93%E8%80%83%E6%8B%89%E6%B5%B7%E8%B4%AD?refer_flag=1001030001_" usercard="name=ç½‘æ˜“è€ƒæ‹‰æµ·è´­&amp;refer_flag=1001030001" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_at" target="_blank" class="W_linkb">@ç½‘æ˜“è€ƒæ‹‰æµ·è´­</a> å‘ç°äº†ä¸€ä»¶ä¸é”™çš„ä¸œä¸œï¼šHero <em class="red">Baby</em> å©´å„¿<em class="red">å¥¶ç²‰</em> 4æ®µ 700å…‹/ç›’ 3ç›’è£… 1-2å² å›´è§‚çŒ›æˆ³è¿™é‡Œ: <a title="http://www.kaola.com/product/28428.html" href="http://t.cn/RqrRkFl" target="_blank" mt="url" action-type="feed_list_url" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_url" class="W_linkb">http://t.cn/RqrRkFl</a>
		</p>
<p class="comment_txt" node-type="feed_list_content" nick-name="R_qiong">
		ä»Šå¤©åœ¨ä¼ è¯´ä¸­æœ€é è°±çš„ <a href="http://weibo.com/n/%E7%BD%91%E6%98%93%E8%80%83%E6%8B%89%E6%B5%B7%E8%B4%AD?refer_flag=1001030001_" usercard="name=ç½‘æ˜“è€ƒæ‹‰æµ·è´­&amp;refer_flag=1001030001" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_at" target="_blank" class="W_linkb">@ç½‘æ˜“è€ƒæ‹‰æµ·è´­</a> å‘ç°äº†ä¸€ä»¶ä¸é”™çš„ä¸œä¸œï¼šHero <em class="red">Baby</em> å©´å„¿<em class="red">å¥¶ç²‰</em> 4æ®µ 700å…‹/ç›’ 3ç›’è£… 1-2å² å›´è§‚çŒ›æˆ³è¿™é‡Œ: <a title="http://www.kaola.com/product/28428.html" href="http://t.cn/RqrRkFl" target="_blank" mt="url" action-type="feed_list_url" suda-data="key=tblog_search_weibo&amp;value=weibo_feed_url" class="W_linkb">http://t.cn/RqrRkFl</a>
		</p>


class UserInfoParser(WeiboParser):
    def parse(self, url=None):
        if self.bundle.exists is False:
            return
        print("1")
        url = url or self.url
        br = self.opener.browse_open(url)
        self.logger.debug('load %s finish' % url)
        soup = beautiful_soup(br.response().read())

        if not self.check(url, br):
            return

        weibo_user = self.get_weibo_user()
        info = weibo_user.info
        if info is None:
            weibo_user.info = UserInfo()

        new_style = False

        profile_div = None
        career_div = None
        edu_div = None
        tags_div = None
        for script in soup.find_all('script'):
            text = script.text
            if text.startswith('FM.view'):
                text = text.strip().replace(';', '').replace('FM.view(', '')[:-1]
                data = json.loads(text)
                domid = data['domid']
                if domid.startswith('Pl_Official_LeftInfo__'):
                    info_soup = beautiful_soup(data['html'])
                    info_div = info_soup.find('div', attrs={'class': 'profile_pinfo'})
                    for block_div in info_div.find_all('div', attrs={'class': 'infoblock'}):
                        block_title = block_div.find('form').text.strip()
                        if block_title == u'åŸºæœ¬ä¿¡æ¯':
                            profile_div = block_div
                        elif block_title == u'å·¥ä½œä¿¡æ¯':
                            career_div = block_div
                        elif block_title == u'æ•™è‚²ä¿¡æ¯':
                            edu_div = block_div
                        elif block_title == u'æ ‡ç­¾ä¿¡æ¯':
                            tags_div = block_div
                elif domid.startswith('Pl_Official_PersonalInfo__'):
                    new_style = True
                    info_soup = beautiful_soup(data['html'])
                    for block_div in info_soup.find_all('div', attrs={'class': 'WB_cardwrap'}):
                        block_title_div = block_div.find('h4', attrs={'class': 'obj_name'})
                        if block_title_div is None:
                            block_title_div = block_div.find('div', attrs={'class': 'obj_name'})\
                                .find('h2')
                        if block_title_div is None:
                            continue
                        block_title = block_title_div.text.strip()
                        inner_div = block_div.find('div', attrs={'class': 'WB_innerwrap'})
                        if block_title == u'åŸºæœ¬ä¿¡æ¯':
                            profile_div = inner_div
                        elif block_title == u'å·¥ä½œä¿¡æ¯':
                            career_div = inner_div
                        elif block_title == u'æ•™è‚²ä¿¡æ¯':
                            edu_div = inner_div
                        elif block_title == u'æ ‡ç­¾ä¿¡æ¯':
                            tags_div = inner_div
                elif domid == 'Pl_Official_Header__1':
                    header_soup = beautiful_soup(data['html'])
                    weibo_user.info.avatar = header_soup.find('div', attrs={'class': 'pf_head_pic'})\
                                                .find('img')['src']
                    weibo_user.info.n_follows = int(header_soup.find('ul', attrs={'class': 'user_atten'})\
                                                    .find('strong', attrs={'node-type': 'follow'}).text)
                    weibo_user.info.n_fans = int(header_soup.find('ul', attrs={'class': 'user_atten'})\
                                                 .find('strong', attrs={'node-type': 'fans'}).text)
                elif domid.startswith('Pl_Core_T8CustomTriColumn__'):
                    # new style friends info
                    header_soup = beautiful_soup(data['html'])
                    tds = header_soup.find('table', attrs={'class': 'tb_counter'})\
                                                .find_all('td')
                    weibo_user.info.n_follows = int(tds[0].find('strong').text)
                    weibo_user.info.n_fans = int(tds[1].find('strong').text)
                elif domid.startswith('Pl_Official_Headerv6__'):
                    # new style avatar info
                    header_soup = beautiful_soup(data['html'])
                    weibo_user.info.avatar = header_soup.find('p', attrs='photo_wrap')\
                                                .find('img')['src']
            elif 'STK' in text:
                text = text.replace('STK && STK.pageletM && STK.pageletM.view(', '')[:-1]
                data = json.loads(text)
                pid = data['pid']
                if pid == 'pl_profile_infoBase':
                    profile_div = beautiful_soup(data['html'])
                elif pid == 'pl_profile_infoCareer':
                    career_div = beautiful_soup(data['html'])
                elif pid == 'pl_profile_infoEdu':
                    edu_div = beautiful_soup(data['html'])
                elif pid == 'pl_profile_infoTag':
                    tags_div = beautiful_soup(data['html'])
                elif pid == 'pl_profile_photo':
                    soup = beautiful_soup(data['html'])
                    weibo_user.info.avatar = soup.find('img')['src']

        profile_map = {
            u'æ˜µç§°': {'field': 'nickname'},
            u'æ‰€åœ¨åœ°': {'field': 'location'},
            u'æ€§åˆ«': {'field': 'sex',
                    'func': lambda s: True if s == u'ç”·' else False},
            u'ç”Ÿæ—¥': {'field': 'birth'},
            u'åšå®¢': {'field': 'blog'},
            u'ä¸ªæ€§åŸŸå': {'field': 'site'},
            u'ç®€ä»‹': {'field': 'intro'},
            u'é‚®ç®±': {'field': 'email'},
            u'QQ': {'field': 'qq'},
            u'MSN': {'field': 'msn'}
        }
        if profile_div is not None:
            if not new_style:
                divs = profile_div.find_all(attrs={'class': 'pf_item'})
            else:
                divs = profile_div.find_all('li', attrs={'class': 'li_1'})
            for div in divs:
                if not new_style:
                    k = div.find(attrs={'class': 'label'}).text.strip()
                    v = div.find(attrs={'class': 'con'}).text.strip()
                else:
                    k = div.find('span', attrs={'class': 'pt_title'}).text.strip().strip(u'ï¼š')
                    d = div.find('span', attrs={'class': 'pt_detail'})
                    if d:
                        v = d.text.strip()
                    else:
                        v = div.find('a').text.strip()
                if k in profile_map:
                    if k == u'ä¸ªæ€§åŸŸå' and '|' in v:
                        v = v.split('|')[1].strip()
                    func = (lambda s: s) \
                            if 'func' not in profile_map[k] \
                            else profile_map[k]['func']
                    v = func(v)
                    setattr(weibo_user.info, profile_map[k]['field'], v)

        weibo_user.info.work = []
        if career_div is not None:
            if not new_style:
                for div in career_div.find_all(attrs={'class': 'con'}):
                    work_info = WorkInfo()
                    ps = div.find_all('p')
                    for p in ps:
                        a = p.find('a')
                        if a is not None:
                            work_info.name = a.text
                            text = p.text
                            if '(' in text:
                                work_info.date = text.strip().split('(')[1].strip(')')
                        else:
                            text = p.text
                            if text.startswith(u'åœ°åŒºï¼š'):
                                work_info.location = text.split(u'ï¼š', 1)[1]
                            elif text.startswith(u'èŒä½ï¼š'):
                                work_info.position = text.split(u'ï¼š', 1)[1]
                            else:
                                work_info.detail = text
                    weibo_user.info.work.append(work_info)
            else:
                li = career_div.find('li', attrs={'class': 'li_1'})
                for span in li.find_all('span', attrs={'class': 'pt_detail'}):
                    work_info = WorkInfo()

                    text = span.text
                    a = span.find('a')
                    if a is not None:
                        work_info.name = a.text
                    if '(' in text:
                        work_info.date = text.strip().split('(')[1]\
                                            .replace('\r', '')\
                                            .replace('\n', '')\
                                            .replace('\t', '')\
                                            .split(')', 1)[0]

                    for l in text.split('\r\n'):
                        l = l.strip()
                        if len(l) == 0:
                            continue
                        if l.startswith(u'åœ°åŒºï¼š'):
                            work_info.location = l.split(u'ï¼š', 1)[1]
                        elif l.startswith(u'èŒä½ï¼š'):
                            work_info.position = l.split(u'ï¼š', 1)[1]
                        else:
                            work_info.detail = text.replace('\r', '')\
                                                    .replace('\n', '')\
                                                    .replace('\t', '')\
                                                    .strip()

                    weibo_user.info.work.append(work_info)

        weibo_user.info.edu = []
        if edu_div is not None:
            if not new_style:
                for div in edu_div.find_all(attrs={'class': 'con'}):
                    edu_info = EduInfo()
                    ps = div.find_all('p')
                    for p in ps:
                        a = p.find('a')
                        text = p.text
                        if a is not None:
                            edu_info.name = a.text
                            if '(' in text:
                                edu_info.date = text.strip().split('(')[1].strip().strip(')')
                        else:
                            edu_info.detail = text
                    weibo_user.info.edu.append(edu_info)
            else:
                span = edu_div.find('li', attrs={'class': 'li_1'})\
                                .find('span', attrs={'class': 'pt_detail'})
                text = span.text
                names = []
                for a in span.find_all('a'):
                    names.append(a.text)

                for idx, name in enumerate(names):
                    start_pos = text.find(name) + len(name)
                    if idx < len(names) - 1:
                        end_pos = text.find(names[idx+1], start_pos)
                    else:
                        end_pos = len(text)
                    t = text[start_pos: end_pos]

                    edu_info = EduInfo()
                    edu_info.name = name
                    if '(' in text:
                        edu_info.date = t.strip().split('(')[1]\
                                            .replace('\r', '')\
                                            .replace('\n', '')\
                                            .replace('\t', '')\
                                            .split(')', 1)[0]
                        t = t[t.find(')')+1:]
                    text = text[end_pos:]
                    edu_info.detail = t.replace('\r', '').replace('\n', '')\
                                        .replace('\t', '').strip()
                    weibo_user.info.edu.append(edu_info)

        weibo_user.info.tags = []
        if tags_div is not None:
            if not new_style:
                for div in tags_div.find_all(attrs={'class': 'con'}):
                    for a in div.find_all('a'):
                        weibo_user.info.tags.append(a.text)
            else:
                for a in tags_div.find('span', attrs={'class': 'pt_detail'}).find_all('a'):
                    weibo_user.info.tags.append(a.text.strip())

        weibo_user.save()
#         self.logger.debug('parse %s finish' % url)

        # counter add one for the profile url
        self.counter.inc('processed_profile_page', 1)
